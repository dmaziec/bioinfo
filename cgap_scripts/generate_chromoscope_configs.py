from dcicutils import ff_utils
import pandas as pd
import json
import argparse
from pathlib import Path
import boto3
from botocore.exceptions import ClientError
import logging
from botocore.client import Config
import os

chromoscope_config_files = {
    "bam": "Tumor_bam",
    "bamIndex": "Tumor_bam_extra_file",
    "sv": "output_sv_bedpe",
    "drivers": "chromoscope_drivers",
    "vcf": 'tnscope_vcf_snv',
    "vcfIndex": 'tnscope_vcf_snv_indx',
    'vcf2': 'tnscope_vcf_indel',
    'vcf2Index': 'tnscope_vcf_indel_indx'
}

dbmi_bucket_name = "cgap-dbmi-main-application-cgap-dbmi-wfoutput"
dbmi_inform_bucket_name = "informtrial"
def generate_presigned_URL(object_path, expiration=604800):
    """
    Generates a presigned URL that can be used to share a private S3 object.

    Credits: Victoria Stevens

    :param bucket_name: The name of S3 bucket containing private objects.
    :type bucket_name: str
    :param object_path: The relative path of S3 object to be shared.
    :type object_path: str
    :param expiration: The number of seconds the presigned URL is valid for.
    :type expiration: int
    :return: The presigned URL.
    :rtype: string
    """

    bucket_name = dbmi_bucket_name
    if object_path.startswith('tnscope2chromoscope') or object_path.startswith('cnv2chromoscope') or object_path.startswith('config') or object_path.startswith("filtered"):
        bucket_name = dbmi_inform_bucket_name
    # Create low-level S3 service client
    s3_client = boto3.client("s3", config = Config(signature_version = "v4"))

    try:
        # URL generated by AWS user with access to private object
        url = s3_client.generate_presigned_url(
            ClientMethod="get_object",
            Params={
                "Bucket": bucket_name,
                "Key": object_path
            },
            ExpiresIn=expiration,
        )
    except ClientError as client_err:
        logging.error(client_err)
        raise client_err

    # Return the presigned URL as a string
    return url


def upload_file(file_name, bucket_name, object_name=None):
    """
    Upload a file to an S3 bucket.

    :param file_name: File to upload.
    :type file_name: str
    :param bucket_name: Bucket to upload to
    :type bucket_name: str
    :param object_name: S3 object name. If not specified, file_name is used.
    :type object_name: str
    """

    # If S3 object_name was not specified, use file_name
    if object_name is None:
        object_name = os.path.basename(file_name)

    s3_client = boto3.client('s3',  config = Config(signature_version = "v4"))
    try:
        response = s3_client.upload_file(file_name, bucket_name, object_name)
    except ClientError as client_err:
        logging.error(client_err)
        raise client_err
def generate_command(args):

    with open(f'{Path.home()}/.cgap-keys.json') as json_file:
        keys = json.load(json_file)

    ff_key = keys.get(args['auth_key'])

    ff_key_key = ff_key['key']
    ff_key_secret = ff_key['secret']


    samples = ff_utils.search_metadata(
        f"search/?type=Sample&project.display_title={args['project']}",
        key=ff_key,
    )

    portal_url = ff_key['server']
    files = {}

    for s in samples:

        individual_display_title = s['individual']['display_title']
        tissue_type = s['tissue_type']

        if individual_display_title not in files.keys():
            files[individual_display_title] = {"individual_display_title": individual_display_title}

        for processed_file in s['processed_files']:
            processed_file_uuid = processed_file['uuid']
            processed_file_data = ff_utils.search_metadata(
                f"search/?uuid={processed_file_uuid}",
                key=ff_key)

            extension = processed_file_data[0]['file_format']['display_title']
            output_file_name = processed_file_data[0]["href"].split("/")[-1]
            files[individual_display_title][
                f"{tissue_type}_{extension}"] = processed_file_data[0]['upload_key']#f'curl -L {portal_url}{processed_file_data[0]["href"]} --user "{ff_key_key}:{ff_key_secret}" -o {output_file_name}'
            files[individual_display_title][f"{tissue_type}_bam_sample_ID"] = s['bam_sample_id']
            if 'extra_files' in processed_file_data[0].keys():
                output_file_name = processed_file_data[0]["extra_files"][0]["href"].split("/")[-1]
                files[individual_display_title][f"{tissue_type}_{extension}_extra_file"] = processed_file_data[0]["extra_files"][0]['upload_key'] #f'curl -L {portal_url}{processed_file_data[0]["extra_files"][0]["href"]} --user "{ff_key_key}:{ff_key_secret}" -o {output_file_name}'

    sa_project = ff_utils.search_metadata(
            f"search/?type=SomaticAnalysis&project.display_title={args['project']}",
            key=ff_key)

    for sa in sa_project:
        individual_display_title = sa['individual']['display_title']
        for processed_file in sa['processed_files']:
            processed_files = ff_utils.get_metadata(processed_file['uuid'], key=ff_key)
            for file in processed_files['workflow_run_outputs'][0]['output_files']:
                if processed_file['uuid'] == file['value']['uuid']:

                    output_file_name = processed_files["href"].split("/")[-1]
                    files[individual_display_title][file[
                        'workflow_argument_name']] = processed_files["upload_key"]  #f'curl -L {portal_url}{processed_files["href"]} --user "{ff_key_key}:{ff_key_secret}" -o {output_file_name}'
                    if 'extra_files' in processed_files.keys():
                    #    output_file_name = processed_files["extra_files"][0]["href"].split("/")[-1]
                        files[individual_display_title][
                            f"{file['workflow_argument_name']}_extra_file"] = processed_files["extra_files"][0]["upload_key"]  #f'curl -L {portal_url}{processed_files["extra_files"][0]["href"]} --user "{ff_key_key}:{ff_key_secret}" -o {output_file_name}'



    return pd.DataFrame.from_dict(files.values()) #.to_csv(args["output"], index=False, sep ="\t")



if __name__ == '__main__':

    parser = argparse.ArgumentParser(description="Generate a TSV file containing download commands for a somatic project.")
    parser.add_argument("--auth_key", "-a", help="The name of the key in ~/.cgap-keys.json to use")
    parser.add_argument("--project", "-p", help="The name of the project")
    parser.add_argument("--output", "-o", help="Output TSV file")
    args = vars(parser.parse_args())




    dataframe = generate_command(args)[["individual_display_title", "Tumor_bam", "Tumor_bam_extra_file", "output_sv_bedpe", "chromoscope_drivers"]]

    dataframe['vcf'] = 'filtered/TNScope_PASS/' + dataframe['individual_display_title'] + '.tnscope_snv.vcf.gz'
    dataframe['vcfIndex'] ='filtered/TNScope_PASS/' + dataframe['individual_display_title'] + '.tnscope_snv.vcf.gz.tbi'

    dataframe['vcf2'] = 'filtered/TNScope_PASS/' + dataframe['individual_display_title'] + '.tnscope_ind.vcf.gz'
    dataframe['vcf2Index'] = 'filtered/TNScope_PASS/' + dataframe['individual_display_title'] + '.tnscope_ind.vcf.gz.tbi'

    dataframe['cnv'] =  'filtered/PURPLE_min_cn_01/' + dataframe['individual_display_title'] + '.purple_cnv.tsv'
    dataframe['output_sv_bedpe'] = 'filtered/GRIDSS_exclude_imprecise/' + dataframe['individual_display_title'] + '.bedpe'

    dataframe.set_index("individual_display_title", inplace=True)
    dataframe = dataframe.applymap(generate_presigned_URL)

    dataframe.reset_index(inplace=True)
    dataframe['assembly'] = 'hg38'
    dataframe['cancer'] = 'breast cancer'
    dataframe = dataframe.rename(columns = {'Tumor_bam': 'bam', 'Tumor_bam_extra_file': 'bai', 'output_sv_bedpe': 'sv',  'chromoscope_drivers': 'drivers', 'individual_display_title': 'id' })


    with open('config.json', 'w') as file_to_write:
        json.dump(dataframe.to_dict(orient='records'), file_to_write)
    #dataframe.to_json("test.json", orient='records', lines=True)

    upload_file('config.json', dbmi_inform_bucket_name)
    print(f"https://chromoscope.bio/app/?external={generate_presigned_URL('config.json', 432000)}")

